# Vision Transformer (ViT) Model Configuration

vit:
  model_name: "vit_base_patch16_224"
  num_classes: 1000
  pretrained: true
  learning_rate: 0.003
  batch_size: 16
  epochs: 50
  image_size:
    - 224
    - 224
  patch_size: 16
  hidden_size: 768
  num_heads: 12
  num_layers: 12
  mlp_dim: 3072

# Common training settings for ViT
training:
  optimizer: "adam"
  loss_function: "cross_entropy"
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
  dataset_path: "/path/to/dataset"
  validation_split: 0.2
  shuffle_dataset: true
  num_workers: 4
  device: "cuda" # or "cpu"
